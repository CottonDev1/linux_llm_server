"""
Prefect SQL Security Flow

Provides Prefect tasks for SQL security validation that can be integrated
into any SQL-related flow. Includes:

1. Prompt Security Validation - Blocks malicious user prompts
2. Generated SQL Validation - Blocks dangerous SQL statements
3. Combined Security Check Task - Full security validation

Migrated from ZenML sql_security_pipeline.py to use Prefect patterns:
- @task instead of @step
- @flow instead of @pipeline
- Native async/await support
- Prefect artifacts for dashboard reporting
"""

import sys
import os
from typing import Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime

from prefect import task, flow, get_run_logger
from prefect.artifacts import create_markdown_artifact

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from sql_security_service import SQLSecurityService, get_security_service


@dataclass
class SecurityValidationResult:
    """Result from security validation task"""
    is_safe: bool
    sanitized_prompt: str
    original_prompt: str
    error_message: Optional[str]
    reason: Optional[str]
    violations: list
    timestamp: str


@task(
    name="validate_prompt_security",
    description="Validates user prompt for security threats",
    retries=1,
    retry_delay_seconds=5,
    log_prints=True
)
async def validate_prompt_security(
    user_prompt: str,
    log_blocked_attempts: bool = True
) -> SecurityValidationResult:
    """
    Prefect task to validate user prompt for security threats.

    This task checks for:
    - Data modification keywords (DELETE, UPDATE, DROP, etc.)
    - Prompt injection attempts
    - SQL injection patterns

    Args:
        user_prompt: The natural language query from user
        log_blocked_attempts: Whether to log blocked attempts

    Returns:
        SecurityValidationResult with validation details
    """
    logger = get_run_logger()
    logger.info(f"Validating prompt security: '{user_prompt[:50]}...'")

    service = get_security_service()
    result = service.check_request(user_prompt)

    timestamp = datetime.now().isoformat()

    if not result.allowed:
        if log_blocked_attempts:
            logger.warning(f"Security blocked prompt: {result.reason}")

        # Create artifact for dashboard
        await create_markdown_artifact(
            key="security-prompt-blocked",
            markdown=f"""## Security Alert: Prompt Blocked

| Field | Value |
|-------|-------|
| **Timestamp** | {timestamp} |
| **Reason** | {result.reason} |
| **Prompt Preview** | `{user_prompt[:100]}...` |
| **Status** | BLOCKED |
""",
            description="Security validation blocked a suspicious prompt"
        )

        return SecurityValidationResult(
            is_safe=False,
            sanitized_prompt=result.sanitized_prompt,
            original_prompt=user_prompt,
            error_message=result.error,
            reason=result.reason,
            violations=[],
            timestamp=timestamp
        )

    logger.info("Prompt passed security validation")

    # Create success artifact
    await create_markdown_artifact(
        key="security-prompt-validated",
        markdown=f"""## Security Validation: Passed

| Field | Value |
|-------|-------|
| **Timestamp** | {timestamp} |
| **Status** | SAFE |
| **Prompt Length** | {len(user_prompt)} chars |
""",
        description="Prompt security validation passed"
    )

    return SecurityValidationResult(
        is_safe=True,
        sanitized_prompt=result.sanitized_prompt,
        original_prompt=user_prompt,
        error_message=None,
        reason=None,
        violations=[],
        timestamp=timestamp
    )


@task(
    name="validate_sql_security",
    description="Validates generated SQL for security threats",
    retries=1,
    retry_delay_seconds=5,
    log_prints=True
)
async def validate_sql_security(
    generated_sql: str,
    log_blocked_attempts: bool = True
) -> SecurityValidationResult:
    """
    Prefect task to validate generated SQL for security threats.

    This task checks for:
    - Forbidden SQL keywords (INSERT, UPDATE, DELETE, DROP, etc.)
    - Statement chaining attempts
    - UNION injection patterns
    - Time-based attack patterns

    Args:
        generated_sql: The SQL query generated by LLM
        log_blocked_attempts: Whether to log blocked attempts

    Returns:
        SecurityValidationResult with validation details
    """
    logger = get_run_logger()
    logger.info(f"Validating SQL security: '{generated_sql[:100]}...'")

    service = get_security_service()
    result = service.validate_generated_sql(generated_sql)

    timestamp = datetime.now().isoformat()

    if not result.safe:
        if log_blocked_attempts:
            logger.warning(f"Security blocked SQL: {result.violations}")

        # Create artifact for dashboard
        await create_markdown_artifact(
            key="security-sql-blocked",
            markdown=f"""## Security Alert: SQL Blocked

| Field | Value |
|-------|-------|
| **Timestamp** | {timestamp} |
| **Violations** | {', '.join(result.violations)} |
| **SQL Preview** | `{generated_sql[:100]}...` |
| **Status** | BLOCKED |
""",
            description="Security validation blocked dangerous SQL"
        )

        return SecurityValidationResult(
            is_safe=False,
            sanitized_prompt="",
            original_prompt=generated_sql,
            error_message=result.error,
            reason="sql_validation_failed",
            violations=result.violations,
            timestamp=timestamp
        )

    logger.info("SQL passed security validation")

    await create_markdown_artifact(
        key="security-sql-validated",
        markdown=f"""## SQL Security Validation: Passed

| Field | Value |
|-------|-------|
| **Timestamp** | {timestamp} |
| **Status** | SAFE |
| **SQL Length** | {len(generated_sql)} chars |
""",
        description="SQL security validation passed"
    )

    return SecurityValidationResult(
        is_safe=True,
        sanitized_prompt=generated_sql,
        original_prompt=generated_sql,
        error_message=None,
        reason=None,
        violations=[],
        timestamp=timestamp
    )


@task(
    name="full_security_check",
    description="Combined security check for prompt and SQL",
    retries=1,
    retry_delay_seconds=5,
    log_prints=True
)
async def full_security_check(
    user_prompt: str,
    generated_sql: Optional[str] = None,
    log_blocked_attempts: bool = True
) -> tuple:
    """
    Combined security check for both prompt and SQL.

    This task performs a complete security validation:
    1. Validates user prompt for malicious intent
    2. If SQL is provided, validates it for dangerous operations

    Args:
        user_prompt: User's natural language query
        generated_sql: Optional generated SQL to validate
        log_blocked_attempts: Whether to log blocked attempts

    Returns:
        Tuple of (is_safe, sanitized_prompt_or_sql, error_message)
    """
    logger = get_run_logger()
    logger.info("Running full security check")

    service = get_security_service()

    # Validate prompt first
    prompt_check = service.check_request(user_prompt)

    if not prompt_check.allowed:
        if log_blocked_attempts:
            logger.warning(f"Security check failed at prompt stage: {prompt_check.reason}")
        return (False, prompt_check.sanitized_prompt, prompt_check.error or "")

    # If SQL provided, validate it too
    if generated_sql:
        sql_check = service.validate_generated_sql(generated_sql)
        if not sql_check.safe:
            if log_blocked_attempts:
                logger.warning(f"Security check failed at SQL stage: {sql_check.violations}")
            return (False, prompt_check.sanitized_prompt, sql_check.error or "")

    logger.info("Full security check passed")

    # Create success artifact
    await create_markdown_artifact(
        key="security-full-check-passed",
        markdown=f"""## Full Security Check: Passed

| Check | Status |
|-------|--------|
| **Prompt Validation** | PASSED |
| **SQL Validation** | {'PASSED' if generated_sql else 'N/A'} |
| **Timestamp** | {datetime.now().isoformat()} |
""",
        description="Full security validation completed successfully"
    )

    return (True, prompt_check.sanitized_prompt, "")


@task(
    name="log_security_event",
    description="Logs security validation events for audit",
    log_prints=True
)
async def log_security_event(
    validation_result: SecurityValidationResult,
    source: str = "unknown"
) -> Dict[str, Any]:
    """
    Log security validation events for audit purposes.

    This task creates an audit record of security validations,
    useful for security monitoring and compliance.

    Args:
        validation_result: The result from a security validation task
        source: Identifier for the source system/pipeline

    Returns:
        Dict with audit record details
    """
    logger = get_run_logger()

    audit_record = {
        "timestamp": validation_result.timestamp,
        "source": source,
        "is_safe": validation_result.is_safe,
        "reason": validation_result.reason,
        "violations": validation_result.violations,
        "prompt_preview": validation_result.original_prompt[:100] if validation_result.original_prompt else None
    }

    if validation_result.is_safe:
        logger.info(f"Security audit: ALLOWED - {source}")
    else:
        logger.warning(f"Security audit: BLOCKED - {source} - {validation_result.reason}")

    # Create audit artifact
    status_emoji = "OK" if validation_result.is_safe else "BLOCKED"
    await create_markdown_artifact(
        key=f"security-audit-{source}",
        markdown=f"""## Security Audit Record

| Field | Value |
|-------|-------|
| **Timestamp** | {audit_record['timestamp']} |
| **Source** | {source} |
| **Status** | {status_emoji} |
| **Reason** | {audit_record['reason'] or 'N/A'} |
| **Violations** | {', '.join(audit_record['violations']) if audit_record['violations'] else 'None'} |
""",
        description=f"Security audit record from {source}"
    )

    return audit_record


@flow(
    name="sql_security_validation_flow",
    description="Complete SQL Security Validation Flow",
    log_prints=True
)
async def sql_security_validation_flow(
    user_prompt: str,
    source: str = "api"
) -> Dict[str, Any]:
    """
    Complete SQL Security Validation Flow.

    This flow validates user prompts for security threats
    and creates audit records.

    Args:
        user_prompt: The natural language query to validate
        source: Identifier for the source system

    Returns:
        Audit record with validation results
    """
    logger = get_run_logger()
    logger.info(f"Starting SQL security validation flow for source: {source}")

    # Task 1: Validate prompt security
    validation_result = await validate_prompt_security(
        user_prompt=user_prompt,
        log_blocked_attempts=True
    )

    # Task 2: Log security event for audit
    audit_record = await log_security_event(
        validation_result=validation_result,
        source=source
    )

    # Create flow summary artifact
    await create_markdown_artifact(
        key="security-flow-summary",
        markdown=f"""## SQL Security Validation Flow Summary

### Input
- **Source**: {source}
- **Prompt Length**: {len(user_prompt)} characters

### Result
- **Status**: {'SAFE' if validation_result.is_safe else 'BLOCKED'}
- **Reason**: {validation_result.reason or 'N/A'}

### Audit
- **Timestamp**: {audit_record['timestamp']}
- **Violations**: {len(validation_result.violations)}
""",
        description="SQL Security Validation Flow Summary"
    )

    return audit_record


def run_security_validation(user_prompt: str, source: str = "manual") -> Dict[str, Any]:
    """
    Convenience function to run the security validation flow synchronously.

    Example:
        from sql_pipeline.prefect.sql_security_flow import run_security_validation

        result = run_security_validation(
            user_prompt="show me all tickets from last month",
            source="sql-query-ui"
        )
        print(f"Is safe: {result['is_safe']}")
    """
    import asyncio
    return asyncio.run(sql_security_validation_flow(
        user_prompt=user_prompt,
        source=source
    ))


# Export individual tasks for use in other flows
__all__ = [
    'validate_prompt_security',
    'validate_sql_security',
    'full_security_check',
    'log_security_event',
    'sql_security_validation_flow',
    'run_security_validation',
    'SecurityValidationResult'
]


if __name__ == "__main__":
    # Test the flow
    print("=== SQL Security Flow Test ===\n")

    # Safe query test
    print("Test 1: Safe query")
    try:
        result = run_security_validation("show me all tickets from last month", "test")
        print(f"  Result: {result}\n")
    except Exception as e:
        print(f"  Error: {e}\n")

    # Dangerous query test
    print("Test 2: Dangerous query")
    try:
        result = run_security_validation("delete all records from Users", "test")
        print(f"  Result: {result}\n")
    except Exception as e:
        print(f"  Error: {e}\n")
