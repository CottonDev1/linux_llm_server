[Unit]
Description=LLaMA Embedding Model Server (Nomic-Embed on GPU 1)
After=network.target

[Service]
Type=simple
User=chad
Group=chad
Environment="CUDA_VISIBLE_DEVICES=1"
ExecStart=/data/projects/llama.cpp/build/bin/llama-server \
    -m /data/models/nomic-embed-text-v1.5-f16.gguf \
    --host 0.0.0.0 \
    --port 8083 \
    --n-gpu-layers 99 \
    --embedding \
    --metrics --ctx-size 512
Restart=on-failure
RestartSec=10
StandardOutput=append:/data/logs/llama/embedding.log
StandardError=append:/data/logs/llama/embedding.log

[Install]
WantedBy=multi-user.target
